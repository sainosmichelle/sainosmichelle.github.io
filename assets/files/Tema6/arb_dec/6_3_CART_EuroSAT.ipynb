{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.3 CART_EuroSAT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdOsJQXC22o7"
      },
      "source": [
        "# 1. Árbol de decisión para clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWoKHztTswt4"
      },
      "source": [
        "**Objetivo:** entrenar y probar un modelo de árbol de decisión para clasificar tipo de uso de suelo a partir de imágenes satelitales.\r\n",
        "\r\n",
        "\r\n",
        "Este dataset es usado para clasificar el uso de suelo en imágenes geoespaciales. \r\n",
        "https://www.kaggle.com/apollo2506/eurosat-dataset\r\n",
        "\r\n",
        "**Información de las características**\r\n",
        "Este dataset contiene imágenes que pertenecen all dataset de EuroSat. Hay 10 folders:\r\n",
        "* 0 AnnualCrop\r\n",
        "* 1 Forest\r\n",
        "* 2 HerbaceousVegatation\r\n",
        "* 3 Highway\r\n",
        "* 4 Industrial\r\n",
        "* 5 Pasture\r\n",
        "* 6 PermanentCrop\r\n",
        "* 7 Residential\r\n",
        "* 8 River\r\n",
        "* 9 SeaLake\r\n",
        "\r\n",
        "\r\n",
        "**Número de instancias:** 27000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k39uYW4e29iO"
      },
      "source": [
        "# 2. Autenticación a Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmkTStln0HVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7cd96b-94d3-4389-c741-87b984559217"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs7rDzqy3XzE"
      },
      "source": [
        "# 3. Importando librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6SZhx1S3Ce5"
      },
      "source": [
        "import ____ as pd\r\n",
        "import ___ #Sistema operativo\r\n",
        "import numpy as ___\r\n",
        "import itertools\r\n",
        "from sklearn.____ import confusion_matrix\r\n",
        "import _____ as plt\r\n",
        "import random\r\n",
        "import ____ as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOFHKcMvn4pK"
      },
      "source": [
        "from ______ import LabelEncoder\r\n",
        "from ______ import MinMaxScaler\r\n",
        "from ______ import PCA\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.____ import DecisionTreeClassifier\r\n",
        "from sklearn.tree import plot_tree\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwz_Fy1q3by6"
      },
      "source": [
        "# 4. Lectura del archivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylkqq-9B3egZ"
      },
      "source": [
        "file_path = _________\r\n",
        "images_path = _______ # Path de las imágenes de Eurosat\r\n",
        "train_path = os.path.join(_____,'EUROSAT_TRAIN_FEAT.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgrpfWgmDfUr"
      },
      "source": [
        "train_df = pd.____(____)\r\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7-pB_rBxMhm"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8giO0Hd_QCgJ"
      },
      "source": [
        "clases = train_df['label'].unique()\r\n",
        "clases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMOeAd0jEUwr"
      },
      "source": [
        "# 5. Exploración de datos (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZygUewEvX_"
      },
      "source": [
        "plt.figure(figsize=(20,20))\r\n",
        "for i,folder in enumerate(clases):\r\n",
        "    path_folder = os.path.join(images_path, folder)\r\n",
        "    imgs_list =os.listdir(path_folder)\r\n",
        "    random.shuffle(imgs_list)\r\n",
        "    for j in range(3):\r\n",
        "      img_path = os.path.join(path_folder,imgs_list[j])\r\n",
        "      plt.subplot(10,10,j*10+i+1)\r\n",
        "      img = plt.imread(img_path)\r\n",
        "      plt.imshow(img)\r\n",
        "      plt.tick_params(axis='both',which='both', bottom=False, top=False, left=False, right=False,\r\n",
        "                        labelbottom=False, labelleft=False)\r\n",
        "      if j==2:\r\n",
        "        plt.xlabel(folder,\r\n",
        "        horizontalalignment='center',\r\n",
        "        verticalalignment='top', fontsize=13)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvnobpWV3fHj"
      },
      "source": [
        "# 6. Limpieza de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfhZ3EVHW0v"
      },
      "source": [
        "#### a) Escalamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GkK3jmO3nps"
      },
      "source": [
        "scaler = _______(feature_range=(___, ___))\r\n",
        "train_df.loc[:, train_df.columns != 'label'] = scaler.______(train_df.loc[:, train_df.columns != 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OyK6zL7D9QV"
      },
      "source": [
        "#### b) Codificación de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDslBREQD8fk"
      },
      "source": [
        "le = ____()\r\n",
        "train_df['label'] = le._______(train_df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bHtEDvIEFc"
      },
      "source": [
        "### c) Análisis de componentes principales con varianza acumulada de al menos el 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BR4vhujFpuz"
      },
      "source": [
        "pca = ____(0.8)\r\n",
        "pc = pca._____(train_df.iloc[:,:-1])\r\n",
        "df_pca_train = pd.DataFrame(data = pc,\r\n",
        "                           columns=range(pc.shape[1]))\r\n",
        "df_pca_train = pd.concat([df_pca_train, train_df[['label']]], axis = 1)\r\n",
        "df_pca_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRcXJcsq4Hrt"
      },
      "source": [
        "Imprimiendo el poder explicativo y el número de componentes principales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_SLNNJz4Bi1"
      },
      "source": [
        "print('Número de componentes principales: %s'%len(___.explained_variance_ratio_))\r\n",
        "print('Varianza acumulada con %s componentes: %s'%(len(pca._____),np.sum(____.explained_variance_ratio_)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2DxxIh5K85l"
      },
      "source": [
        "Renombrando a las columnas del dataframe df_pca_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDqSA3dOKAl"
      },
      "source": [
        "feat_names = ['PC_'+str(i+1) for i in range(len(pca.explained_variance_ratio_))]\r\n",
        "df_pca_train.columns=feat_names+['label']\r\n",
        "print(feat_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWDNTL8VBT1Q"
      },
      "source": [
        "g = sns.PairGrid(data=df_pca_train, vars=feat_names, hue='label', size=2)\r\n",
        "g.map_diag(plt.hist)\r\n",
        "g.map_offdiag(plt.scatter)\r\n",
        "g.add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjzdbZYbP2o7"
      },
      "source": [
        "# 7. Modelo de árbol de decisión CART usando Holdout validation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvobSAZiP1fX"
      },
      "source": [
        "seed = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbsGJc834PFb"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(_____, train_df['label'], test_size = ____, random_state = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHzloiGbjgFY"
      },
      "source": [
        "n_classes = len(clases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eeh3kyg0-Mjp"
      },
      "source": [
        "# 8. Creando modelo "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xF6BF6GdReM"
      },
      "source": [
        "c) Instanciando un árbol de decisión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAv2ks19MAFO"
      },
      "source": [
        "dectree = ______(random_state=seed, max_depth = ___)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y-qP2bgdcSa"
      },
      "source": [
        "d) Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0w_2hAxcO7F"
      },
      "source": [
        "dectree = dectree._____(____,____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR767k4xC9rR"
      },
      "source": [
        "**Score de entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkIPHD9fDCol"
      },
      "source": [
        "dectree.score(_____,_____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3mOpXCCDC-Y"
      },
      "source": [
        "Plot del árbol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VSUKsT0Nw8E"
      },
      "source": [
        "plt.figure(figsize = (25,12))\r\n",
        "plot_tree(dectree, feature_names = feat_names, class_names = clases, filled = True, fontsize=8)\r\n",
        "plt.savefig('dectree_eurosat.png',format='png',bbox_inches = \"tight\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDDs5OMdwTU"
      },
      "source": [
        "# 8. Prediciendo para los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWz2rOZdugl"
      },
      "source": [
        "y_pred = dectree._____(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaP1c8M6d3tq"
      },
      "source": [
        "a) Calculando el rendimiento general del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNyu0hmtd24t"
      },
      "source": [
        "score = metrics.accuracy_score(____, ____)\r\n",
        "print(\"Test Acc: %s\"%____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwIGzJcYeqFn"
      },
      "source": [
        "b) Predicciones vs etiquetas verdaderas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nop_BuBYd9GD"
      },
      "source": [
        "predictions = np.float32(_____)\r\n",
        "true_labels = np.float32(_____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddyF8ZlgfkNX"
      },
      "source": [
        "c) Matriz de confusión para evaluar los errores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgmRZWPmgSRh"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, tit, normalize=False):\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float')/cm.sum(axis=1)\r\n",
        "        title, fmt = 'Matriz de confusión normalizada', '.2f'\r\n",
        "    else:\r\n",
        "        title, fmt = tit, 'd'\r\n",
        "    plt.figure(figsize=(10,8))\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\r\n",
        "    plt.title(title)#, fontsize=12)\r\n",
        "    plt.colorbar(pad=0.05)\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=40)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "    thresh = cm.max()/2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\", \r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('Clase Verdadera', fontsize=10)\r\n",
        "    plt.xlabel('Clase Predicha', fontsize=10)\r\n",
        "    plt.savefig(title+'.png')\r\n",
        "    #plt.grid(b=None)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTUYife4fBiT"
      },
      "source": [
        "cnf_matrix = confusion_matrix(______, _______, labels=range(n_classes))\r\n",
        "tit = 'Matriz de confusión árbol de decisión (CART)'\r\n",
        "plot_confusion_matrix(cnf_matrix,clases, tit, normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvGfeQiGupbg"
      },
      "source": [
        "e) Otras métricas para evaluar el rendimiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFrJ9TnPEaYk"
      },
      "source": [
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "acc=[]\r\n",
        "for i,name in enumerate(df_pca_train.label.unique()):\r\n",
        "  TP = np.sum((true_labels==name) & (predictions==name))\r\n",
        "  TN = np.sum((true_labels!=name) & (predictions!=name))\r\n",
        "  FP = np.sum((true_labels!=name) & (predictions==name))\r\n",
        "  FN = np.sum((true_labels==name) & (predictions!=name))\r\n",
        "  sensitivity.append(TP/(TP+FN))\r\n",
        "  specificity.append(FP/(TN+FP))\r\n",
        "  acc.append(TP/(TP+FP))\r\n",
        "sensitivity.append(sum([x*y for x,y in zip(sensitivity,[1/10]*10)]))\r\n",
        "specificity.append(sum([x*y for x,y in zip(specificity,[1/10]*10)]))\r\n",
        "acc.append(sum([x*y for x,y in zip(acc,[1/10]*10)]))\r\n",
        "d = {'Sensitivity':sensitivity, 'Specificity':specificity, 'Accuracy':acc}\r\n",
        "ind = list(clases)+['Promedio']\r\n",
        "df = pd.DataFrame(d, index=ind)\r\n",
        "index = df.index\r\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\r\n",
        "sns.heatmap(df, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uszJc15JEsAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}